{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TP2 : Reconstruction tomographique\n",
    "### Physique Numérique (PHY-3500)\n",
    "### Par: Simon Gauthier, Laurent Émond, Thomas Charland\n",
    "### Présenté à: Xavier Roy-Pomerleau\n",
    "### Remis le: 23 mars 2025"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mise en contexte"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'arrivée de l'ordinateur a révolutionné la médecine moderne en permettant d'utiliser des méthodes d'imagerie nécessitant sur une puissance de calcul élevée. La tomodensitométrie (TDM), qui permet d'estimer la distribution de la densité d'un objet à partir de plusieurs mesures d'atténuation [1], est l'une de ces méthodes. La tomodensitométrie est majoritairement utilisée pour l'analyse de zones non-visibles par d'autres examens d'imagerie médicale [2], et permet d'obtenir des résultat de l'ordre du millimètre [1]\n",
    "\n",
    "Ce notebook résout le TP2 du cours de Physique Numérique (PHY-3500). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importer toutes les libraries nécessaires pour la résolution du TP\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import recon as recon\n",
    "from PIL import Image\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Numéro 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En utilisant la base de donnée XCOM du NIST [3], nous obtenons un coefficient d'atténuation $\\mu = 2.059 \\cdot 10^{-1}$ cm^2/g pour un photon de 60KeV voyageant dans l'eau à 1.0 g/cm^3. Afin d'identifier, la fraction du signal qui subsistera au parcours indiqué, nous utiliserons la loi de Beer-Lambert :\n",
    "$\n",
    "\\begin{align}\n",
    "ln\\left( \\frac{I_0}{I} \\right) &= \\sum \\mu(x) \\delta x\\\\\n",
    "\\frac{I_0}{I} &= e^{\\left( \\sum \\mu(x) \\delta x \\right)}\n",
    "\\end{align}\n",
    "$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code pour résoudre le numéro 1\n",
    "def remaining_intensity(attenuation_coefs_of_media : list, distance_travelled_in_media : list):\n",
    "    sum_value = 0\n",
    "    for i in range(len(attenuation_coefs_of_media)):\n",
    "        sum_value += attenuation_coefs_of_media[i] * distance_travelled_in_media[i]\n",
    "    \n",
    "    remaining_intensity = 100 * math.e**(-sum_value)\n",
    "    return remaining_intensity / 100\n",
    "\n",
    "print(f\"La fraction du signal subsistant après 5cm est: {remaining_intensity([0.2059], [5]):.5f}\")\n",
    "print(f\"La fraction du signal subsistant après 20cm est: {remaining_intensity([0.2059], [20]):.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En utilisant l'équation 2, nous avons déterminé qu'après avoir traversé 5 cm d'eau, la fraction du signal restante est de 35,72 %. Après 20 cm d'eau, elle n'est plus que de 1,62 %."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Numéro 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Une manière simple (et un peu naïve) de reconstruire une image à partir d'un sinogramme tomodensitométrique est d'identifier les rayons qui passent par chaque voxel et de les sommer afin d'obtenir la valeur du pixel [1]. L'image ainsi obtenue est nommée laminogramme. En utilisant cette méthode, dite *voxel-driven*, nous obtenons les images suivantes pour les sinogrammes *sinogram-password.txt* et *sinogram-patient.txt*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geo\n",
    "import util\n",
    "\n",
    "# Nous débutons avec un fonction permettant de lire une image et de la transformer en une matrice de valeurs\n",
    "def readInput(angle_file: str, sinogram_file: str) -> list[int, np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Cette fonction permet de lire les fichiers d'angles et de sinogramme.\n",
    "\n",
    "    angle_file: le fichier contenant les angles de projection\n",
    "    sinogram_file: le fichier contenant le sinogramme\n",
    "\n",
    "    return: nombre de projections, les angles de projection et le sinogramme\n",
    "    \"\"\"\n",
    "    # lire les angles\n",
    "    [nbprj, angles] = util.readAngles(angle_file)\n",
    "\n",
    "    # Debug\n",
    "    #print(\"nbprj:\",nbprj)\n",
    "    #print(\"angles min and max (rad):\")\n",
    "    #print(\"[\"+str(np.min(angles))+\", \"+str(np.max(angles))+\"]\")\n",
    "\n",
    "    # lire le sinogramme\n",
    "    [nbprj2, nbpix2, sinogram] = util.readSinogram(sinogram_file)\n",
    "\n",
    "    if nbprj != nbprj2:\n",
    "        print(\"Lecture des fichiers d'angles et de sinogramme conflictuelle!\")\n",
    "        exit(0)\n",
    "\n",
    "    if geo.nbpix != nbpix2:\n",
    "        print(\"Lecture des fichiers d'angles et de sinogramme conflictuelle!\")\n",
    "        exit(0)\n",
    "\n",
    "    return [nbprj, angles, sinogram]\n",
    "    \n",
    "# Nous poursuivons avec une fonction permettant d'imager les données sous forme de laminogram\n",
    "def laminogram(data_input: list[int, np.ndarray, np.ndarray]) -> None:\n",
    "    \n",
    "    [nbprj, angles, sinogram] = data_input\n",
    "    \n",
    "    # initialiser une image reconstruite\n",
    "    image = np.zeros((geo.nbvox, geo.nbvox))\n",
    "\n",
    "    # \"etaler\" les projections sur l'image\n",
    "    # ceci sera fait de façon \"voxel-driven\"\n",
    "    # pour chaque voxel, trouver la contribution du signal reçu\n",
    "    for j in range(geo.nbvox): # colonnes de l'image\n",
    "        print(f\"\\rWorking on image column: {str(j+1)}/{str(geo.nbvox)}\", end=\"\", flush=True)\n",
    "        for i in range(geo.nbvox): # lignes de l'image\n",
    "            for a in range(0, len(angles), 1):\n",
    "                            \n",
    "                mid_ray = geo.nbpix/2 # indice du rayon central\n",
    "                mid_vox = geo.nbvox/2 # indice du voxel central en x et en y\n",
    "                angle = angles[a]\n",
    "                proj = sinogram[a]\n",
    "\n",
    "                # déterminer si le rayon est dirigé vers la gauche ou la droite\n",
    "                # l'algorithme est fait pour les rayons dirigés vers la gauche\n",
    "                # on peut corriger à la fin pour les rayons dirigés vers la droite\n",
    "                ray_dir = \"left\" if angle < np.pi else \"right\"\n",
    "\n",
    "                # angle entre 0 et pi\n",
    "                angle %= np.pi\n",
    "\n",
    "                # position en voxels relative au centre de la grille de reconstruction\n",
    "                current_vox_x = j - mid_vox\n",
    "                current_vox_y = mid_vox - i\n",
    "\n",
    "                # paramètre d'une droite passant par le voxel courant et la pente du rayon actuel\n",
    "                m = np.tan(angle + np.pi/2)\n",
    "                b = current_vox_y - m * current_vox_x\n",
    "\n",
    "                # vecteur perpendiculaire à la droite mx+b et allant vers le centre de la grille\n",
    "                perp_vector = [m*b/(m**2 + 1), -b/(m**2 + 1)]\n",
    "\n",
    "                # norme et angle du vecteur perpendiculaire\n",
    "                norm_to_center = np.linalg.norm(perp_vector)\n",
    "                angle_to_center = np.arctan2(perp_vector[1], perp_vector[0])\n",
    "\n",
    "                # décalage en pixels (détecteur) à partir du centre du détecteur pour avoir le rayon\n",
    "                # croisant le voxel courant\n",
    "                if np.isnan(angle_to_center): # si le courant est au centre de la grille, le vecteur est nul\n",
    "                    ray_index = mid_ray\n",
    "                \n",
    "                else: # on ajuste le décalage en fonction de si le vecteur perpendiculaire\n",
    "                    # pointe dans la même direction que le l'axe du détecteur ou non\n",
    "                    # Si les angles sont opposés, le décalage doit être inversé \n",
    "                    # (sens contraire de t dans la figure 2 de l'énoncé)\n",
    "\n",
    "                    n_ray_shift = norm_to_center * geo.voxsize / geo.pixsize # convertis n_voxels à n_pixels/n_rays\n",
    "\n",
    "                    if int(angle_to_center) == int(angle):\n",
    "                        factor = 1\n",
    "                    else:\n",
    "                        factor = -1\n",
    "                    \n",
    "                    if ray_dir == \"right\": # si le rayon est dirigé vers la droite (angle initial > pi avant le modulo)\n",
    "                                           # on flip l'image dans les deux axes pour garder le même algorithme\n",
    "                        i = geo.nbvox - i - 1\n",
    "                        j = geo.nbvox - j - 1\n",
    "                    \n",
    "                    ray_index = int(mid_ray + n_ray_shift * factor)\n",
    "\n",
    "                image[i, j] += proj[ray_index]\n",
    "\n",
    "    util.saveImage(image, \"laminogram\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Une fois notre code correctement établi, nous pouvons l'utiliser pour générer un laminogramme à partir des données contenues dans le fichier sinogram-password.txt. Ce laminogramme offre une représentation visuelle du mot de passe, comme illustré dans la figure ci-dessous. Une fois le mot de passe identifié à partir de cette image reconstruite, il peut être utilisé pour accéder au fantôme numérique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lire les données du fichier d'angles et de password \"sinogram-password.txt\"\n",
    "data_input = readInput(geo.dataDir + geo.anglesFile, geo.dataDir + geo.pwSinogramFile)\n",
    "# Créer le laminogram\n",
    "laminogram(data_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ci-dessous se trouvent tous les laminogrammes générés à partir des données fournies dans l'énoncé. Les dimensions de chaque image sont également indiquées sous chaque laminogramme, afin de fournir des informations supplémentaires sur la taille et la résolution de chaque représentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code pour résoudre le numéro 2\n",
    "\n",
    "print(\"Laminogramme obtenu du sinogram-password:\\n\")\n",
    "image = mpimg.imread('mot_de_passe.png')\n",
    "plt.imshow(image)\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "image = Image.open('mot_de_passe.png')\n",
    "width, height = image.size\n",
    "print(f\"Dimension : {width} X {height} \\n\")\n",
    "\n",
    "print(\"Laminogramme obtenu du sinogram-patient:\\n\")\n",
    "image = mpimg.imread('laminogramme.png')\n",
    "plt.imshow(image)\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "image = Image.open('laminogramme.png')\n",
    "width, height = image.size\n",
    "print(f\"Dimension : {width} X {height} \\n\")\n",
    "\n",
    "\n",
    "print(\"Image du fantôme numérique:\\n\")\n",
    "image = mpimg.imread('phantom-thorax-096-smooth.png')\n",
    "plt.imshow(image, cmap=\"gray\")\n",
    "plt.axis('off') \n",
    "plt.show()\n",
    "image = Image.open('phantom-thorax-096-smooth.png')\n",
    "width, height = image.size\n",
    "print(f\"Dimension : {width} X {height} \")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trois différences majeures sont identifiables entre le sinogramme du patient et le fantôme numérique:\n",
    "\n",
    "- le contraste est plus fort sur l'image du fantôme numérique que sur celle du laminogramme. Lors de la création du laminogramme, le fait d’étaler les projections sur la grille de l’image ajoute beaucoup de composantes de basse fréquence spatiale dans l’image [1]; nous nous retrouvons alors avec un contraste plus faible sur le laminogramme que sur le fantôme initiale. Cela fait en sorte que nous perdons plusieurs détails de l'image; dans ce cas-ci, nous perdons entièrement la position des os ainsi que les tâches dans les poumons, ce qui rend le laminogramme ainsi obtenu inutile d'un point de vue médical!\n",
    "\n",
    "- l'image du fantôme numérique est plus pixelisée que celle du laminogramme. En effet, l'image du fantôme numérique a une dimension de 96x96, alors que le laminogramme obtenu est de 192x192. Ceci est simplement dû au fait que, lors de la reconstruction des voxels, nous avons utilisé une matrice 192x192 comme grille virtuelle de reconstruction; en vérité, nous ne gagnons pas d'information supplémentaire avec cette pixelisation augmentée.\n",
    "\n",
    "- Il est également possible de constater que la MTF (Modulation Transfer Function) [4] associée à notre traitement d'image est très faible pour les hautes fréquences spatiales. En effet, nous observons que notre traitement d'image a des difficultés à rendre les hautes fréquences spatiales. Cela peut être mis en évidence en se concentrant sur la zone de transition entre le patient et le vide de l'image. Sur le fantôme, la délimitation est franche et nette, ce qui correspond à des hautes fréquences spatiales, tandis que sur l'image traitée, la transition est plus progressive, indiquant une dominance de basses fréquences spatiales. Ce phénomène suggère que le traitement a atténué les détails fins de l'image ou amplifié les basses férquences, réduisant ainsi la capacité à distinguer les transitions abruptes.\n",
    "\n",
    "\n",
    "Il faut certainement améliorer l'image obtenue si l'on veut pouvoir utiliser le laminogramme à des fins médicales! C'est ce que nous ferons au numéro suivant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Numéro 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comme mentionné dans le paragraphe précédent, les hautes fréquences sont largement sous-représentées dans l'image produite par le laminogramme. Pour remédier à cela, il est possible d'effectuer un filtrage des données du sinogramme. L'application d'un filtre passe-haut permettrait de réduire l'amplitude des basses fréquences afin de mieux mettre en évidence les hautes fréquences. Ces dernières sont en effet déterminantes pour la capacité de résolution de notre traitement d'image.\n",
    "\n",
    "Dans notre cas, le filtre passe bas sera appliqué ligne par ligne. En d'autre mots, chaque ligne du sinogramme sera filtré via une fft selon l'algorithme suivant : \n",
    "\n",
    "$\n",
    "\\begin{align}\n",
    "    P(u) &= F[p(t)] \\\\\n",
    "    P_f(u) &= P(u) \\times |u| \\\\\n",
    "    p_f(t) &= F^{-1}[P(u) \\times |u|]\n",
    "\\end{align}\n",
    "$\n",
    "où $p(t)$ et $p_f(t)$ sont respectivement le signal temporel non-filtré et filtré. Aussi, $F$ représente l'opérateur de la tranformé de fourrier et $|u|$ est notre filtre passe-haut rudimentaire (une rampe)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## filtrer le sinogramme\n",
    "## ligne par ligne\n",
    "def filterSinogram(sinogram):\n",
    "    for i in range(sinogram.shape[0]):\n",
    "        sinogram[i] = filterLine(sinogram[i])\n",
    "    return sinogram\n",
    "\n",
    "## filter une ligne (projection) via FFT\n",
    "def filterLine(projection):\n",
    "    fft_proj = np.fft.fft(projection)\n",
    "    fft_proj = np.fft.fftshift(fft_proj)\n",
    "    \n",
    "    freqs = np.fft.fftfreq(len(projection))\n",
    "\n",
    "    # filtre en rampe\n",
    "    ramp = np.abs(freqs)\n",
    "    ramp = 1 - ramp/np.max(ramp)\n",
    "\n",
    "    # appliquer le filtre\n",
    "    fft_proj = fft_proj*ramp\n",
    "\n",
    "    # retourner dans l'espace des fréquences\n",
    "    fft_proj = np.fft.ifftshift(fft_proj)\n",
    "    filtered_proj = np.fft.ifft(fft_proj)\n",
    "\n",
    "    return np.real(filtered_proj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Appliquons maintenant cet algorithm à notre sinograme."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## visualiser le sinogramme avant et après filtrage\n",
    "[_, _, sinogram] = readInput(geo.dataDir + geo.anglesFile, geo.dataDir + geo.pwSinogramFile)\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(sinogram, cmap='gray')\n",
    "sinogram = filterSinogram(sinogram)\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(sinogram, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il est désormais possible de confirmer que notre algorithme filtre correctement nos données, comme prévu. En effet, une observation attentive au centre de l'image (à l'intersection) montre que les différents signaux (traits) sont plus fins et mieux définis après le filtrage. Il est ainsi plus facile de distinguer les signaux qui se croisent dans l'image filtrée que dans l'image non filtrée, où les transitions sont moins nettes. Nous pouvons maintenant présenter les observations officielles concernant notre sinogramme, tant dans sa version non filtrée que filtrée. Ces deux versions de l'image nous offrent la possibilité de comparer l'impact du filtrage sur les données et d'évaluer plus précisément les améliorations apportées par l'algorithme."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code pour résoudre le numéro 3\n",
    "print(\"Sinogramme patient original (fourni):\\n\")\n",
    "image = mpimg.imread('sinogram-patient.png')\n",
    "plt.imshow(image)\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "print(\"Sinogramme patient filtré passe-haut:\\n\")\n",
    "image = mpimg.imread('sinogram-patient-filtered.png')\n",
    "plt.imshow(image, cmap=\"gray\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bien qu'il soit qualitativement évident que les deux sinnogrammes proviennent du même set de données, plusieurs différences sont observées:\n",
    "\n",
    "- Comme l'on s'y attend, seulement les haute fréquences sont conservées une fois le sinogramme filtré. Cela fait donc en sorte que nous voyons très facilement les zones de contraste (c'est sont d'ailleurs les zones qui, de manière générale, nous intéressent le plus d'un point de vue médicale), alors qu'elles sont moins évidents dans le graphique non-filtré. \n",
    "\n",
    "- De plus, l'on observe que l'intensité des pixels sur l'image est moindre pour le sinogramme filtré. Cela est également attendu puisqu'en filtrant les basses fréquence, nous éliminons les composantes \"DC\" qui rehaussent les valeurs des pixels de larges plages spatiales. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Numéro 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maintenant que nous avons filtré le sinogramme, nous pouvons reconstruire l'image du fantôme numérique. Pour ce faire, nous allons utiliser la méthode de rétroprojection filtrée. Nous allons d'abord définir la fonction de rétroprojection filtrée. Pour ce faire nous nous baserons fortement sur la méthode utilisé au "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backproject(data_input: list[int, np.ndarray, np.ndarray]) -> None:\n",
    "    \n",
    "    [nbprj, angles, sinogram] = data_input\n",
    "    \n",
    "    # initialiser une image reconstruite\n",
    "    image = np.zeros((geo.nbvox, geo.nbvox))\n",
    "    \n",
    "    ### option filtrer ###\n",
    "    sinogram = filterSinogram(sinogram)\n",
    "    ######\n",
    "    \n",
    "    # \"etaler\" les projections sur l'image\n",
    "    # ceci sera fait de façon \"voxel-driven\"\n",
    "    # pour chaque voxel, trouver la contribution du signal reçu\n",
    "    for j in range(geo.nbvox): # colonnes de l'image\n",
    "        print(f\"\\rWorking on image column: {str(j+1)}/{str(geo.nbvox)}\", end=\"\", flush=True)\n",
    "        for i in range(geo.nbvox): # lignes de l'image\n",
    "            for a in range(0, len(angles), 1):\n",
    "                            \n",
    "                mid_ray = geo.nbpix/2 # indice du rayon central\n",
    "                mid_vox = geo.nbvox/2 # indice du voxel central en x et en y\n",
    "                angle = angles[a]\n",
    "                proj = sinogram[a]\n",
    "\n",
    "                # déterminer si le rayon est dirigé vers la gauche ou la droite\n",
    "                # l'algorithme est fait pour les rayons dirigés vers la gauche\n",
    "                # on peut corriger à la fin pour les rayons dirigés vers la droite\n",
    "                ray_dir = \"left\" if angle < np.pi else \"right\"\n",
    "\n",
    "                # angle entre 0 et pi\n",
    "                angle %= np.pi\n",
    "\n",
    "                # position en voxels relative au centre de la grille de reconstruction\n",
    "                current_vox_x = j - mid_vox\n",
    "                current_vox_y = mid_vox - i\n",
    "\n",
    "                # paramètre d'une droite passant par le voxel courant et la pente du rayon actuel\n",
    "                m = np.tan(angle + np.pi/2)\n",
    "                b = current_vox_y - m * current_vox_x\n",
    "\n",
    "                # vecteur perpendiculaire à la droite mx+b et allant vers le centre de la grille\n",
    "                perp_vector = [m*b/(m**2 + 1), -b/(m**2 + 1)]\n",
    "\n",
    "                # norme et angle du vecteur perpendiculaire\n",
    "                norm_to_center = np.linalg.norm(perp_vector)\n",
    "                angle_to_center = np.arctan2(perp_vector[1], perp_vector[0])\n",
    "\n",
    "                # décalage en pixels (détecteur) à partir du centre du détecteur pour avoir le rayon\n",
    "                # croisant le voxel courant\n",
    "                if np.isnan(angle_to_center): # si le courant est au centre de la grille, le vecteur est nul\n",
    "                    ray_index = mid_ray\n",
    "                \n",
    "                else: # on ajuste le décalage en fonction de si le vecteur perpendiculaire\n",
    "                    # pointe dans la même direction que le l'axe du détecteur ou non\n",
    "                    # Si les angles sont opposés, le décalage doit être inversé \n",
    "                    # (sens contraire de t dans la figure 2 de l'énoncé)\n",
    "\n",
    "                    n_ray_shift = norm_to_center * geo.voxsize / geo.pixsize # convertis n_voxels à n_pixels/n_rays\n",
    "\n",
    "                    if int(angle_to_center) == int(angle):\n",
    "                        factor = 1\n",
    "                    else:\n",
    "                        factor = -1\n",
    "                    \n",
    "                    if ray_dir == \"right\": # si le rayon est dirigé vers la droite (angle initial > pi avant le modulo)\n",
    "                                        # on flip l'image dans les deux axes pour garder le même algorithme\n",
    "                        i = geo.nbvox - i - 1\n",
    "                        j = geo.nbvox - j - 1\n",
    "                    \n",
    "                    ray_index = int(mid_ray + n_ray_shift * factor)\n",
    "\n",
    "                image[i, j] += proj[ray_index]\n",
    "\n",
    "    util.saveImage(image, \"Rétroprojection filtrée\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lire les données du fichier d'angles et de \"sinogram-patient.txt\"\n",
    "data_input = readInput(geo.dataDir + geo.anglesFile, geo.dataDir + geo.ptSinogramFile)\n",
    "# Créer le laminogram\n",
    "backproject(data_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous pouvons remarquer que la netteté de notre image s'est grandement améliorée, avec une définition des détails beaucoup plus précise et des contours plus nets. Cette amélioration rend maintenant pertinente une comparaison approfondie entre notre nouvelle image filtrée et le fantôme, afin de mieux évaluer la précision et la fidélité des résultats obtenus par notre algorithme de traitement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code pour résoudre le numéro 4\n",
    "print(\"Laminogramme obtenu du sinogram-patient filtré passe-haut:\\n\")\n",
    "image = mpimg.imread('backproject.png')\n",
    "plt.imshow(image)\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "print(\"Fantôme numérique initial:\\n\")\n",
    "image = mpimg.imread('phantom-thorax-096-smooth.png')\n",
    "plt.imshow(image, cmap=\"gray\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow, cela fait toute une différence vs le sinogramme non-filtré! L'on remarque toutefois deux différences majeurs avec le fantôme initial:\n",
    "\n",
    "- encore une fois, la résolution du laminogramme est supérieure à celle du fantôme numérique. Comme à la question 2, cela est dû au fait que nous représentons les voxels sur une grille 192x192, alors que le fantôme numérique est une image de taille 96x96. Il est important de préciser que, comme précédemment, nous ne gagnons pas d'informations supplémentaire avec cette résolution supérieure, bien qu'elle soit plus agréable à regarder!\n",
    "\n",
    "- il y a quelques artéfacts dans le laminogramme produit à partir du sinogramme filtré. Ces artéfacts se produisent à une fréquence spatiale d'environ 6-8 pixels, et sont surtout visibles dans les secteurs pâles de l'image du laminogramme. Ils sont dû très certainement au filtre, qui élimine les basses fréquence, ce qui explique pourquoi nous remarquons ces erreurs à une basse fréquence spatiale. \n",
    "\n",
    "De manière générale, le laminogramme produit à partir du sinogramme filtré est de bien meilleure utilité pour le domaine médicale que ne l'était le laminogramme produit à partir du sinogramme non-filtré."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Numéro 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tel que demandé dans l'énoncé, nous implémenterons une seconde méthode permettant d'obtenir les images en TDM. La fonction $\\textit{reconFourierSlice}$ reconstruit une image à partir de projections TDM en utilisant le théorème de la tranche de Fourier. Elle applique d’abord une transformée de Fourier 1D aux projections du sinogramme, puis projette ces données dans l’espace de Fourier 2D en les positionnant selon leurs angles. Une interpolation est effectuée pour adapter ces données polaires à une grille cartésienne. Enfin, une transformée de Fourier inverse 2D est appliquée pour obtenir l’image reconstruite, qui est ensuite enregistrée."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.interpolate import griddata\n",
    "\n",
    "## reconstruire une image TDM en mode retroprojection\n",
    "def reconFourierSlice(data_input: list[int, np.ndarray, np.ndarray]) -> None:\n",
    "    \n",
    "    [nbprj, angles, sinogram] = data_input\n",
    "\n",
    "    sinogram = np.fft.ifftshift(sinogram, axes=1)\n",
    "    sinogram = np.fft.fft(sinogram, axis=1)\n",
    "    sinogram = np.fft.fftshift(sinogram, axes=1)\n",
    "\n",
    "    theta = angles\n",
    "    s = sinogram.shape[1]\n",
    "    r = np.arange(s) - s/2\n",
    "    \n",
    "    R, Theta = np.meshgrid(r, theta)\n",
    "    x = R*np.cos(Theta)\n",
    "    y = R*np.sin(Theta)\n",
    "\n",
    "    x_flat = x.flatten()\n",
    "    y_flat = y.flatten()\n",
    "    v_flat = sinogram.flatten()\n",
    "\n",
    "    grid_x, grid_y = np.meshgrid(\n",
    "        np.arange(-geo.nbvox/2, geo.nbvox/2),\n",
    "        np.arange(-geo.nbvox/2, geo.nbvox/2)\n",
    "    )\n",
    "    \n",
    "    IMAGE = griddata(\n",
    "        (x_flat, y_flat),\n",
    "        v_flat,\n",
    "        (grid_x, grid_y),\n",
    "        method='cubic',\n",
    "        fill_value=1e7,\n",
    "    )\n",
    "\n",
    "    image = np.fft.ifft2(IMAGE)\n",
    "    image = np.fft.ifftshift(image)\n",
    "    image = np.abs(image)\n",
    "\n",
    "    util.saveImage(image, \"Fourier slice theorem\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lire les données du fichier d'angles et de \"sinogram-patient.txt\"\n",
    "data_input = readInput(geo.dataDir + geo.anglesFile, geo.dataDir + geo.ptSinogramFile)\n",
    "# Créer le laminogram\n",
    "reconFourierSlice(data_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voici l'image reconstruite par le théorème de la tranche de Fourier. Qualitativement, l'image obtenue présente une netteté similaire à celle obtenue avec la méthode de la rétroprojection filtrée. En effet, la résolution de l'image semble plutôt comparable. Cependant, il est important de mentionner que cette méthode permet d’obtenir un résultat équivalent sans avoir à filtrer les projections. De plus, le temps de calcul est nettement inférieur : 4,7 s pour cette méthode contre 5 min 25 s pour la méthode basée sur les rétroprojections."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bibliographie"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[1] TP2 : Reconstruction tomographique, D. Matenine et P. Després, *PHY-3500– Physique num´erique (H25)*\n",
    "\n",
    "[2] Pourquoi réaliser une tomodentometrie, Information hospitalière, <https://www.informationhospitaliere.com/tomodensitometrie-deroulement-precautions-et-effets-secondaires#Pourquoi_realiser_une_tomodensitometrie%E2%80%89>\n",
    "\n",
    "[3] XCOM database, NIST, <https://physics.nist.gov/PhysRefData/Xcom/html/xcom1.html>\n",
    "\n",
    "[4] Jerrold T. Bushberg The Essential Physics of Medical Imaging"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
