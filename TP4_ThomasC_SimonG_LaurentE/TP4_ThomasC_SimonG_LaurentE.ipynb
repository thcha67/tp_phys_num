{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TP4\n",
    "### Physique Numérique (PHY-3500)\n",
    "### Par: Simon Gauthier, Laurent Émond, Thomas Charland\n",
    "### Présenté à: Xavier Roy-Pomerleau et Antoine Allard\n",
    "### Remis le: 14 avril 2025"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TP4.1 Intégration numérique de la dynamique épidémiologique SIS (50 points)\n",
    "\n",
    "#### a)\n",
    "\n",
    "On peut simplement solutionner analytiquement l'équation quadratique suivante:\n",
    "$$\n",
    "0=(R_0-1)i-R_0i^2\n",
    "$$\n",
    "On trouve donc que les solutions, ou états stationnaires, sont:\n",
    "$$\n",
    "i^*_1=0\\qquad\\qquad i^*_2=1-\\frac{1}{R_0}\n",
    "$$\n",
    "Puisque $i^*_{1,2}$ doit être dans l'intervalle [0,1], cela impose les valeurs $R_0\\ge1$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b)\n",
    "\n",
    "En utilisant $\\frac{di}{d\\tau}=i'$, on peut placer dans la forme de Bernouilli, soit $i'+p(\\tau)i=q(\\tau)i^n$:\n",
    "$$\n",
    "    i'+(1-R_0)i=(-R_0)i^2\n",
    "$$\n",
    "où $p(\\tau)=1-R_0$, $q(\\tau)=(-R_0)$ et $n=2$.\n",
    "\n",
    "On peut alors diviser par $i^{-n}=i^{-2}$:\n",
    "$$\n",
    "    i^{-2}i'+(1-R_0)i^{-1}=-R_0\n",
    "$$\n",
    "On utilise ensuite la substitution $v=i^{1-n}=i^{-1}$. \n",
    "$$\n",
    "    v^2i'+(1-R_0)v=-R_0\n",
    "$$\n",
    "On doit également trouver $i'$ en fonction de $v$. On peut dériver implicitement notre substitution et isoler $i'$, soit $i'=-i^2v'=-\\frac{1}{v^2}v'$. On remplace:\n",
    "$$\n",
    "-v'+(1-R_0)v=-R_0\n",
    "$$\n",
    "On divise par $-1$:\n",
    "$$\n",
    "v'+(R_0-1)v=R_0\n",
    "$$\n",
    "Cette EDO en $v$ est linéaire, on peut donc la résoudre à l'aide de la méthode du facteur d'intégration $\\mu(\\tau)$. On multiplie donc l'équation par $\\mu(\\tau)$:\n",
    "$$\n",
    "v'\\mu(\\tau)+(R_0-1)v\\mu(\\tau)=R_0\\mu(\\tau)\n",
    "$$\n",
    "On assume pour l'instant la condition $\\mu(\\tau)(R_0-1)=\\mu'(\\tau)$. On a donc:\n",
    "$$\n",
    "v'\\mu(\\tau)+v\\mu'(\\tau)=R_0\\mu(\\tau)\n",
    "$$\n",
    "On remarque que le côté gauche est simplement la dérivée du produit $v\\mu(\\tau)$. On a donc:\n",
    "$$\n",
    "(v\\mu(\\tau))'=R_0\\mu(\\tau)\n",
    "$$\n",
    "On intègre alors des deux côtés par rapport à $\\tau$ et on obtient:\n",
    "$$\n",
    "v\\mu(\\tau)+C=\\int R_0\\mu(\\tau) d\\tau\n",
    "$$\n",
    "où $C$ est notre constante d'intégration. On isole $v$:\n",
    "$$\n",
    "v=\\frac{\\int R_0\\mu(\\tau) d\\tau - C}{\\mu(\\tau)}\n",
    "$$\n",
    "Maintenant, sachant que $\\frac{\\mu'(\\tau)}{\\mu(\\tau)}=R_0-1$, on trouve que $\\mu(\\tau)=e^{\\int (R_0-1) d\\tau + k}=Ke^{(R_0-1)\\tau}$ où $K=e^k$ est une constante d'intégration. On a donc:\n",
    "$$\n",
    "v=\\frac{K\\int R_0e^{(R_0-1)\\tau} d\\tau - \\frac{C}{k}}{Ke^{(R_0-1)\\tau}}\n",
    "$$\n",
    "On définit $c_1=\\frac{c}{K}$ pour avoir:\n",
    "$$\n",
    "\\begin{align*}\n",
    "v&=\\frac{\\int R_0e^{(R_0-1)\\tau} d\\tau - c_1}{e^{(R_0-1)\\tau}}\\\\\n",
    "&=\\frac{\\frac{R_0}{R_0-1}e^{(R_0-1)\\tau}+c_2-c_1}{e^{(R_0-1)\\tau}}\\\\\n",
    "&=\\frac{\\frac{R_0}{R_0-1}e^{(R_0-1)\\tau}+C}{e^{(R_0-1)\\tau}}\n",
    "\\end{align*}\n",
    "$$\n",
    "où $C=c_2-c_1$ est une constante. On peut alors exprimer $v$ en fonction de $i$ et isoler $i$:\n",
    "$$\n",
    "i=\\frac{1}{v}=\\frac{e^{(R_0-1)\\tau}}{\\frac{R_0}{R_0-1}e^{(R_0-1)\\tau}+C}\n",
    "$$\n",
    "On peut ensuite utiliser une condition initiale $i(0)=i_0$ pour obtenir:\n",
    "$$\n",
    "i_0=\\frac{e^{(R_0-1)0}}{\\frac{R_0}{R_0-1}e^{(R_0-1)0}+C}=\\frac{1}{\\frac{R_0}{R_0-1}+C}\n",
    "$$\n",
    "On a donc:\n",
    "$$\n",
    "C= \\frac{R_0-1-R_0i_0}{i_0(R_0-1)}\n",
    "$$\n",
    "On a donc:\n",
    "$$\n",
    "i(\\tau)=\\frac{e^{(R_0-1)\\tau}}{\\frac{R_0}{R_0-1}e^{(R_0-1)\\tau}+\\frac{R_0-1-R_0i_0}{i_0(R_0-1)}}=\\frac{i_0(R_0-1)e^{(R_0-1)\\tau}}{i_0R_0e^{(R_0-1)\\tau}+R_0-1-i_0R_0}\n",
    "$$\n",
    "pour $\\tau>0$. Cela impose la branche positive de la solution particulière, soit $i>0$.\n",
    "\n",
    "On peut tracer cette solution pour une condition initiale $i_0=0.5$ et une valeur $R_0=1.5$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analytical(times, R0, i0):\n",
    "    \"\"\" Solution particulière analytique du modèle SIR.\"\"\"\n",
    "    return (i0*(R0-1)*np.exp((R0-1)*times))/(i0*R0*np.exp((R0-1)*times)+R0-1-i0*R0)\n",
    "\n",
    "\n",
    "R0 = 2 # nombre de personnes infectées par une personne infectée\n",
    "i0 = 0.1 # proportion d'infectés au temps t=0\n",
    "\n",
    "times = np.linspace(0, 10, 1000)\n",
    "\n",
    "plt.plot(times, analytical(times, R0, i0))\n",
    "plt.title(fr\"Solution particulière analytique pour $R_0={R0}$ et $i_0={i0}$\")\n",
    "plt.xlabel(r\"Temps sans dimension $\\tau$\")\n",
    "plt.ylabel(r\"Proportion d'infectés\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c)\n",
    "On implémente ici les trois intégrateurs numériques demandés. Ces derniers prennent en entrée une variable $T$, qui détermine le nombre de pas de taille $h$ qui seront faits. Par exemple, pour $T=3$, les deux vecteurs retournées (temps et proportion d'infectés) auront une longueur $T+1$ (puisque les indices débutent à 0). Pour le vecteur de temps, les valeurs choisies seront des multiples de $h$, soit $0, h, 2h, ...$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def infection_rate(i, R0):\n",
    "    \"\"\"Dérivée de la fonction d'infection par rapport au temps dans dimension tau\"\"\"\n",
    "    return (R0-1)*i-R0*i**2\n",
    "\n",
    "def euler(T, h, R0, i0):\n",
    "    \"\"\" Méthode d'Euler pour la résolution de l'ODE\"\"\"\n",
    "    i = np.zeros(T+1)\n",
    "    i[0] = i0\n",
    "    for j in range(1, T+1):\n",
    "        i[j] = i[j-1] + h*infection_rate(i[j-1], R0)\n",
    "    return h*np.arange(0, T+1), i\n",
    "\n",
    "def rk2(T, h, R0, i0):\n",
    "    \"\"\" Méthode de Runge-Kutta d'ordre 2 pour la résolution de l'ODE\"\"\"\n",
    "    i = np.zeros(T+1)\n",
    "    i[0] = i0\n",
    "    for j in range(1, T+1):\n",
    "        k1 = h*infection_rate(i[j-1], R0)\n",
    "        k2 = h*infection_rate(i[j-1] + 0.5*k1, R0)\n",
    "        i[j] = i[j-1] + k2\n",
    "    return h*np.arange(0, T+1), i\n",
    "\n",
    "def rk4(T, h, R0, i0):\n",
    "    \"\"\" Méthode de Runge-Kutta d'ordre 4 pour la résolution de l'ODE\"\"\"\n",
    "    i = np.zeros(T+1)\n",
    "    i[0] = i0\n",
    "    for j in range(1, T+1):\n",
    "        k1 = h*infection_rate(i[j-1], R0)\n",
    "        k2 = h*infection_rate(i[j-1] + 0.5*k1, R0)\n",
    "        k3 = h*infection_rate(i[j-1] + 0.5*k2, R0)\n",
    "        k4 = h*infection_rate(i[j-1] + k3, R0)\n",
    "        i[j] = i[j-1] + (k1 + 2*k2 + 2*k3 + k4)/6\n",
    "    return h*np.arange(0, T+1), i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### d)\n",
    "On implémente ici la méthode du ratio dorée pour arriver à isoler une valeur de $h$ pour laquelle la fonction d'erreur donne une valeur entre 0.99 $\\delta$ et 1.01 $\\delta$. Puisque la méthode du ratio doré permet de trouver un minimum d'une fonction, et que l'on veut plutôt une valeur d'erreur dans un certain intervalle, il faut ajouter une étape. En effet, lorsque l'on trouve une valeur de $h$ pour laquelle l'erreur est inférieure à 0.99 $\\delta$, signifiant que nous avons trouvé une solution \"trop\" précise, une interpolation est faite pour approximer le $h$ qui aurait donné une erreur égale à $\\delta$. Puisque l'on sait qu'une relation à peu près linéaire relie les logarithmes de l'erreur et du pas de temps, il est possible d'interpolation linéairement en log-log et de retourner la valeur de $h$ interpolée."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def error(f, T, h, R0, i0):\n",
    "    times, i = f(T, h, R0, i0)\n",
    "    i_analytical = analytical(times, R0, i0)\n",
    "    error = np.sqrt(1/(len(i)+1)*np.sum((i-i_analytical)**2))\n",
    "    return error\n",
    "\n",
    "def golden_ratio_method(f, h1, h4, T, R0, i0, delta, max_iter=100):\n",
    "    z = (1 + np.sqrt(5)) / 2 # nombre d'or\n",
    "    h2 = h4 - (h4-h1)/z\n",
    "    h3 = h1 + (h4-h1)/z\n",
    "\n",
    "    last_h2_log = np.log10(h1)\n",
    "    last_e2_log = np.log10(error(f, T, h1, R0, i0))\n",
    "\n",
    "    for i in range(max_iter):\n",
    "        e2 = error(f, T, h2, R0, i0)\n",
    "        e3 = error(f, T, h3, R0, i0)\n",
    "        if i > 0:\n",
    "            if abs(e2) < 0.99*delta:\n",
    "                # sachant que log(e) est propotionnel à log(h)\n",
    "                # on interpole linéaire pour trouver le h pour lequel\n",
    "                # l'erreur est delta\n",
    "                h2_log = np.log10(h2)\n",
    "                e2_log = np.log10(e2)\n",
    "                log_delta = np.log10(delta)\n",
    "                \n",
    "                interp_h2_log = h2_log - (e2_log - log_delta) * (h2_log - last_h2_log) / (e2_log - last_e2_log)\n",
    "                interp_h2 = 10**interp_h2_log\n",
    "                return interp_h2\n",
    "        \n",
    "        last_h2_log = np.log10(h2)\n",
    "        last_e2_log = np.log10(e2)\n",
    "        \n",
    "        if e2 < e3:\n",
    "            h4, h3 = h3, h2\n",
    "            h2 = h4 - (h4-h1)/z\n",
    "\n",
    "        else:\n",
    "            h2, h1 = h3, h2\n",
    "            h3 = h1 + (h4-h1)/z\n",
    "\n",
    "    raise ValueError(\"La méthode de la section dorée n'a pas convergé dans le nombre d'itérations maximal autorisé.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from IPython.display import display, HTML\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "\n",
    "R0i0_pairs = [(1.5, 0.1), (1.5, 0.9), (2, 0.1), (2, 0.9), (3, 0.1), (3, 0.9)]\n",
    "deltas = [1e-6, 1e-7, 1e-8, 1e-9]\n",
    "\n",
    "delta_R0i0_to_show = [\n",
    "    (1.5, 0.9, 1e-7),\n",
    "    (2, 0.1, 1e-8), \n",
    "    (3, 0.9, 1e-9),\n",
    "]\n",
    "\n",
    "T = 3\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "for delta in deltas:\n",
    "    results = pd.DataFrame(columns=[\"R0/i0\", \"Euler\", \"RK2\", \"RK4\"])\n",
    "\n",
    "    for R0, i0 in R0i0_pairs:\n",
    "        times = np.linspace(0, T, 1000) # finer grid for analytical solution\n",
    "\n",
    "        delta_R0i0 = (R0, i0, delta)\n",
    "\n",
    "        methods_results = []\n",
    "\n",
    "        for j, method in enumerate([euler, rk2, rk4]):\n",
    "            h1 = 1e-10\n",
    "            h4 = 0.1\n",
    "\n",
    "            h = golden_ratio_method(method, h1, h4, T, R0, i0, delta)\n",
    "            t, i = method(T, h, R0, i0)\n",
    "\n",
    "            if delta_R0i0 in delta_R0i0_to_show:\n",
    "                plt.subplot(3, 3, 3*delta_R0i0_to_show.index(delta_R0i0)+j+1)\n",
    "                plt.xlabel(r\"Temps sans dimension $\\tau$\")\n",
    "                plt.ylabel(r\"Proportion d'infectés\")\n",
    "                plt.grid()\n",
    "                plt.plot(times, analytical(times, R0, i0), label=\"Analytique\", linestyle='--')\n",
    "                plt.title(f\"{method.__name__}, R0={R0}, i0={i0}, delta={delta}\")\n",
    "                plt.plot(t, i)\n",
    "                dy = max(i) - min(i)\n",
    "                y_min = min(i) - 0.2 * dy\n",
    "                y_max = max(i) + 0.2 * dy\n",
    "                plt.ylim(y_min, y_max)\n",
    "\n",
    "                dx = max(t) - min(t)\n",
    "                x_min = 0\n",
    "                x_max = max(t) + 0.2 * dx\n",
    "                plt.xlim(x_min, x_max)\n",
    "\n",
    "                # Fonction pour créer 3 ticks arrondis\n",
    "                def round_locator(min_val, max_val):\n",
    "                    range_val = max_val - min_val\n",
    "                    step = 10**np.floor(np.log10(range_val))\n",
    "                    for factor in [1, 2, 2.5, 5]:\n",
    "                        if range_val / (step * factor) <= 4:\n",
    "                            step *= factor\n",
    "                            break\n",
    "                    tick_min = step * np.floor(min_val / step)\n",
    "                    tick_max = step * np.ceil(max_val / step)\n",
    "                    ticks = np.linspace(tick_min, tick_max, 3)\n",
    "                    return np.round(ticks, 8)\n",
    "\n",
    "                # Appliquer les ticks personnalisés\n",
    "                xticks = round_locator(x_min, x_max)\n",
    "                yticks = round_locator(y_min, y_max)\n",
    "                plt.xticks(xticks)\n",
    "                plt.yticks(yticks)\n",
    "\n",
    "                # Forcer notation décimale normale\n",
    "                ax = plt.gca()\n",
    "                ax.ticklabel_format(style='plain', axis='both')  # <- no scientific notation\n",
    "\n",
    "            error_at_h = error(method, T, h, R0, i0)\n",
    "\n",
    "            methods_results.append(f\"{h:.2e} [{error_at_h:.2e}]\")\n",
    "\n",
    "        results.loc[len(results)] = [f\"{R0}/{i0}\"] + methods_results\n",
    "\n",
    "\n",
    "    display(HTML(f\"<h2>Valeur de h[erreur] pour delta = {delta}</h2>\"))\n",
    "    # display datafram without index and with borders\n",
    "    display(HTML(results.to_html(index=False, border=1, justify='center')))\n",
    "\n",
    "plt.suptitle(\"\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On remarque dans les tableaux ci-haut que le comportement est respecté pour la majorité des cas. En effet, on voit que l'erreur (entre crochet) converge dans l'intervalle [0.99, 1.01]$\\delta$. On remarque aussi que la grandeur des pas nécessaire pour atteindre cette précision est plus petite pour Euler que pour RK2 et encore plus que pour RK4. On remarque aussi, tel qu'attendu, qu'il faut un pas plus fin pour atteindre une erreur plus petite.\n",
    "\n",
    "Dans les graphiques, on remarque que les pas choisis permettent de bien suivre la courbe analytique."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### e)\n",
    "On simplement créer un espace logarithmique de valeurs de h et calculer l'erreur pour chacun de ces pas de temps. On prend une échelle logarithmique afin de couvrir un plus écart de pas de temps sans devoir choisir énormément de valeurs. \n",
    "On peut ensuite tracer en échelle logarithmiques ces valeurs de $h$ et d'erreur associée et prendre la pente d'une régression linéaire de ces points.\n",
    "Cette pente nous donne la valeur de l'ordre d'erreur $d$ soit 2.00 pour Euler, 3.00 pour RK2 et 5.01 pour RK4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_h_space_euler = np.logspace(-5, -2, 10)\n",
    "log_h_space_rk2 = np.logspace(-4, -2, 10)\n",
    "log_h_space_rk4 = np.logspace(-2, -1, 10)\n",
    "\n",
    "R0 = 4\n",
    "i0 = 0.1\n",
    "\n",
    "errors_euler = np.array([error(euler, T, h, R0, i0) for h in log_h_space_euler]) # erreur pour chacune des valeurs de T\n",
    "errors_rk2 = np.array([error(rk2, T, h, R0, i0) for h in log_h_space_rk2]) # erreur pour chacune des valeurs de T\n",
    "errors_rk4 = np.array([error(rk4, T, h, R0, i0) for h in log_h_space_rk4]) # erreur pour chacune des valeurs de T\n",
    "\n",
    "T = 3\n",
    "\n",
    "def slope(x, y):\n",
    "    \"\"\" Calcul de la pente d'une régression linéaire \"\"\"\n",
    "    return np.polyfit(x, y, 1)[0]\n",
    "\n",
    "slope_euler = slope(np.log(log_h_space_euler), np.log(errors_euler))\n",
    "slope_rk2 = slope(np.log(log_h_space_rk2), np.log(errors_rk2))\n",
    "slope_rk4 = slope(np.log(log_h_space_rk4), np.log(errors_rk4))\n",
    "\n",
    "plt.scatter(log_h_space_euler, errors_euler, label=f\"Euler (slope={slope_euler:.2f})\")\n",
    "\n",
    "plt.scatter(log_h_space_rk2, errors_rk2, label=f\"RK2 (slope={slope_rk2:.2f})\")\n",
    "plt.scatter(log_h_space_rk4, errors_rk4, label=f\"RK4 (slope={slope_rk4:.2f})\")\n",
    "plt.xscale(\"log\")\n",
    "plt.yscale(\"log\")\n",
    "plt.xlabel(r\"Pas de temps $h$\")\n",
    "plt.ylabel(r\"Erreur $\\epsilon$\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TP4.2 Simulation Monte-Carlo de la dynamique SIS (50 points)\n",
    "\n",
    "#### a)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ici nous sommes en présence d'une situation probabiliste décrit par la Binomiale de paramètre N et P où N représente le nombre totale de liasons possible ($\\frac{n(n - 1)} {2}$) et P représente la probabilité que le liens se concrétise (p). Le résonnement derrière cette expréssion vient du fait qu'il y a un nomrbe de liaisons possible équvalent à ($\\frac{n(n - 1)} {2}$). Pour arriver à cette équation, nous savons que chaque noeud est lié à (n-1) autres noeuds. Cependant, il ne faut pas compter les liens en double. Ensuite, chaque liaisons correspond à une épreuve de Bernouilli de probabilité p. C'est pourquoi que la probabilité d'avoir m liens (succès) est décrit par la loi Binomiale suivante :\n",
    "\n",
    "$$\n",
    "    P(M = m) = \\binom{N}{m} P^m (1-P)^{N-m}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Afin d'obtenir le nombre de lien moyen de notre expréssion, il suffit de calculer l'espérance. L'espérance de la loi Binomiale équivaut à ($N\\cdot P$)[1]. Celle-ci peut être démontré en écriavant la relation binomiale en une sommation de loi de Bernouilli $Y_k$ possédant tous une probabilité identique de P.\n",
    "$$\n",
    "    M = \\sum_{k=1}^{N}Y_{k}\n",
    "$$\n",
    "Il est ainsi possible d'appliquer l'espérance à notre nouvelle équation.\n",
    "$$\n",
    "\\begin{align}\n",
    "    \\mathbb{E}[M] &= \\mathbb{E}\\left[\\sum_{k=1}^{N}Y_{k}\\right]\\\\\n",
    "    &= \\sum_{k=1}^{N}\\mathbb{E}[Y_{k}]\\\\\n",
    "    &= \\sum_{k=1}^{N} P \\\\\n",
    "    &= NP\n",
    "\\end{align}\n",
    "$$ \n",
    "\n",
    "On peut utiliser la même logique pour la variance. De cette manière, nous obtenons que la varaince est égale à $NP(1-P)$\n",
    "$$\n",
    "\\begin{align}\n",
    "    \\mathbb{V}[M] &= \\mathbb{V}\\left[\\sum_{k=1}^{N}Y_{k}\\right]\\\\\n",
    "    &= \\sum_{k=1}^{N}\\mathbb{V}[Y_{k}]\\\\\n",
    "    &= \\sum_{k=1}^{N} P(1-P) \\\\\n",
    "    &= NP(1-P)\n",
    "\\end{align}\n",
    "$$ \n",
    "Finalement, sachant que l'écart-type correspond à la racine de la variance, nous avons que \n",
    "$$\n",
    "    \\sigma = \\sqrt{NP(1-P)}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Avant d'implémenter un algorithme qui génère des graphes en utilisant le modèle d’Erdős–Rényi, nous implémentons certaines fonctions permettant de déterminer théoriquement, grâce à la loi Binomiale, l'espérance, la variance ainsi que l'écart-type. Ces fonctions consiste simplement en l'implémentation des équations identifiés au numéro précédent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_esperance(n, P):\n",
    "    \"\"\"Calcul de l'espérance d'un relation Erdos-Renyi\"\"\"\n",
    "    return n*(n-1)/2 * P\n",
    "\n",
    "def get_variance(n, P):\n",
    "    \"\"\"Calcul de la variance d'un relation Erdos-Renyi\"\"\"\n",
    "    return n*(n-1)*P*(1-P)/2\n",
    "\n",
    "def get_std(n, P):\n",
    "    \"\"\"Calcul de l'écart-type d'un relation Erdos-Renyi\"\"\"\n",
    "    return np.sqrt(get_variance(n, P))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensuite, nous implémentons une classe permettant de construire des graphes en utilisant le modèle d’Erdős–Rényi. Pour ce faire, nous construisons une matrice (N X N) représentant l'ensemble des liens possible entre les noeuds. Le lien à l'adresse (i,j) représente le lien entre le noeuds i et j. Bien entendu, la diagonale est égalé à 0 puisqu'un noeud ne peut pas être lié à lui même. Puisque les liens ne sont pas directionnel ([i,j] = [j,i]) il est possible de garder seulement la partie supérieur de la matrice et de la rendre symétrique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Array_Erdos_Renyi:\n",
    "    def __init__(self, n, p):\n",
    "        self.n = n\n",
    "        self.p = p\n",
    "        self.array = np.random.rand(n, n) < p # Création d'une matrice aléatoire\n",
    "        self.array = np.triu(self.array, 1) # On ne garde que la partie supérieure de la matrice\n",
    "        self.array = self.array + self.array.T # On symétrise la matrice\n",
    "        self.array = self.array.astype(int) # On convertit en entier (False=0, True=1)\n",
    "        np.fill_diagonal(self.array, 0) # On met des 0 sur la diagonale (False=0)\n",
    "\n",
    "    def Get_Nb_Links(self):\n",
    "        \"\"\"Calcul de le nombre de liens seulement dans la partie supérieure de la matrice\"\"\"\n",
    "        return np.sum(self.array[np.triu_indices(self.n, 1)])\n",
    "    \n",
    "    def __str__(self):\n",
    "        return str(self.array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0) # Pour la reproductibilité\n",
    "\n",
    "N_nodes = 100\n",
    "p = 0.2\n",
    "print(f\"Espérance Théorique : {get_esperance(N_nodes, p):.2f}\")\n",
    "print(f\"Variance Théorique : {get_variance(N_nodes, p):.2f}\")\n",
    "print(f\"Ecart-type Théorique : {get_std(N_nodes, p):.2f}\")\n",
    "\n",
    "mean_links = []\n",
    "N_iterations = 1000\n",
    "for i in range(N_iterations):\n",
    "    a = Array_Erdos_Renyi(100, 0.2)\n",
    "    mean_links.append(a.Get_Nb_Links())\n",
    "    \n",
    "print(f\"Espérance Pratique : {np.mean(mean_links):.2f}\")\n",
    "print(f\"Variance Pratique : {np.var(mean_links):.2f}\")\n",
    "print(f\"Ecart-type Pratique : {np.std(mean_links):.2f}\")\n",
    "\n",
    "# Fit de la distribution Binomial\n",
    "from scipy.stats import binom\n",
    "x = np.arange(0, N_nodes*(N_nodes-1)/2 + 1)\n",
    "binom_dist = binom.pmf(x, N_nodes*(N_nodes-1)/2 + 1, p)\n",
    "plt.plot(x, binom_dist, label=\"Distribution Binomiale Théorique\", linestyle='--')\n",
    "plt.hist(mean_links, bins=20, density=True ,label=\"Distribution Pratique\")\n",
    "plt.title(\"Distribution du nombre de liens\")\n",
    "plt.xlabel(\"Nombre de liens\")\n",
    "plt.xlim(np.mean(mean_links)-3*np.std(mean_links), np.mean(mean_links)+3*np.std(mean_links))\n",
    "plt.ylabel(\"Fréquence\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous pouvons observer que l'espérance théorique ainsi que l'écart-type théorique sont très similaire à leurs homologues expérimentaux. Lorsque l'on compare la distribution pratique mesuré avec la distribution théorque, nous remarquons que celles-ci sont très similaire et en accordance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Afin de faciliter l'intégration de la simulation Monte-Carlo aux modules NetworkX, nous implémentons une class directement dérivé de l'objet Graph de NetworkX. À cette classe nous ajoutons des arrays utilisés pour effectuer les différentes étapes de la simulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SIS(nx.Graph):\n",
    "    def __init__(self, network_path, alpha, beta):\n",
    "        \"\"\"Initialisation du modèle SIS\"\"\"\n",
    "        # On charge le réseau\n",
    "        G_temp = nx.read_adjlist(network_path)\n",
    "\n",
    "        # On initialise la classe mère\n",
    "        super().__init__()\n",
    "        self.add_nodes_from(G_temp.nodes(data=True))\n",
    "        self.add_edges_from(G_temp.edges(data=True))\n",
    "\n",
    "        # Initialisation de nos paramètres\n",
    "        self.sis_alpha = alpha  # taux de guérison\n",
    "        self.sis_beta = beta    # taux d'infection\n",
    "        self.sis_N = self.number_of_nodes()  # nombre de noeuds\n",
    "        self.sis_nodes = np.zeros(self.sis_N, dtype=bool)  # tableau des noeuds\n",
    "        self.sis_temp_nodes = np.zeros(self.sis_N, dtype=bool)  # tableau temporaire des noeuds\n",
    "        self.sis_edges = np.zeros((self.sis_N, self.sis_N), dtype=bool)  # tableau des liens\n",
    "\n",
    "        self.sis_nodes_colors = np.zeros(self.sis_N, dtype=str)  # tableau des couleurs\n",
    "        self.sis_nodes_colors[:] = \"c\"  # couleur par défaut\n",
    "\n",
    "        self._set_links_array()  # Initialisation du tableau des liens\n",
    "    \n",
    "    def _init_infected(self, p):\n",
    "        \"\"\"Initialisation des noeuds infectés\"\"\"\n",
    "        self.sis_nodes = np.zeros(self.sis_N, dtype=bool)  # tableau des noeuds\n",
    "        self.sis_nodes[np.random.rand(self.sis_N) < p] = True\n",
    "\n",
    "    def _set_links_array(self):\n",
    "        \"\"\"Initialisation du tableau des liens\"\"\"\n",
    "        for link in self.edges():\n",
    "            i, j = int(link[0]), int(link[1])\n",
    "            self.sis_edges[i, j] = True\n",
    "            self.sis_edges[j, i] = True\n",
    "    \n",
    "    def _reset_temp_nodes(self):\n",
    "        \"\"\"Réinitialisation du tableau temporaire des noeuds\"\"\"\n",
    "        self.sis_temp_nodes[:] = False  # On remet tous les noeuds à 0\n",
    "    \n",
    "    def _compute_healed_nodes(self):\n",
    "        \"\"\"Guérison des noeuds\"\"\"\n",
    "        # On parcourt tous les noeuds\n",
    "        for i in range(self.sis_N):\n",
    "            if self.sis_nodes[i]:\n",
    "                # Si le noeud est infecté, on le guérit avec une probabilité alpha\n",
    "                if np.random.rand() < self.sis_alpha:\n",
    "                    self.sis_nodes[i] = False\n",
    "        \n",
    "    def _infected_linked_to_node(self, index) -> bool:\n",
    "        \"\"\"Infection des noeuds liés à un noeud infecté\"\"\"\n",
    "        ret = False\n",
    "        if self.sis_nodes[index]:\n",
    "            ret = True\n",
    "        else:\n",
    "            if np.random.rand() < self.sis_beta:\n",
    "                ret = True\n",
    "            else:\n",
    "                 pass\n",
    "        return ret\n",
    "\n",
    "    def _compute_infected_nodes(self):\n",
    "        \"\"\"Infection des noeuds\"\"\"\n",
    "        for i in range(self.sis_N):\n",
    "            # On parcourt tous les noeuds\n",
    "            if self.sis_nodes[i]:\n",
    "                # Si le noeud est infecté, on parcourt tous ses voisins\n",
    "                for j in range(self.sis_N):\n",
    "                    if self.sis_edges[i, j]:\n",
    "                        # Si le noeud j est infecté, on l'infecte avec une probabilité beta\n",
    "                        if self._infected_linked_to_node(j):\n",
    "                            # Le noeud j est infecté\n",
    "                            self.sis_temp_nodes[j] = True            \n",
    "            else:\n",
    "                continue\n",
    "        # On met à jour le tableau des noeuds\n",
    "        self.sis_nodes = np.logical_or(self.sis_nodes, self.sis_temp_nodes)\n",
    "        # On réinitialise le tableau temporaire\n",
    "        self._reset_temp_nodes()\n",
    "    \n",
    "    def _set_color_infected_nodes(self):\n",
    "        \"\"\"Mise à jour des couleurs des noeuds\"\"\"\n",
    "        for i in range(self.sis_N):\n",
    "            if self.sis_nodes[i]:\n",
    "                self.sis_nodes_colors[i] = \"r\"\n",
    "            else:\n",
    "                self.sis_nodes_colors[i] = \"c\"\n",
    "    \n",
    "    def init_infected(self, p):\n",
    "        \"\"\"Initialisation des noeuds infectés\"\"\"\n",
    "        self.sis_nodes = np.zeros(self.sis_N, dtype=bool)  # tableau des noeuds\n",
    "        self.sis_nodes[np.random.rand(self.sis_N) < p] = True\n",
    "\n",
    "        # On met à jour les couleurs des noeuds\n",
    "        self._set_color_infected_nodes()\n",
    "\n",
    "    def simulate_one_iteration(self,) -> None:\n",
    "        \"\"\"Simulation d'une itération du modèle SIS\"\"\" \n",
    "        # On guérit les noeuds\n",
    "        self._compute_healed_nodes()\n",
    "        # On infecte les noeuds\n",
    "        self._compute_infected_nodes()\n",
    "        # On met à jour les couleurs des noeuds\n",
    "        self._set_color_infected_nodes()\n",
    "        return None\n",
    "\n",
    "    def simulate_multiple_iteration(self, T) -> None:\n",
    "        \"\"\"Simulation du modèle SIS\"\"\"\n",
    "        for t in range(T):\n",
    "            # On guérit les noeuds\n",
    "            self._compute_healed_nodes()\n",
    "            # On infecte les noeuds\n",
    "            self._compute_infected_nodes()\n",
    "        \n",
    "        # On met à jour les couleurs des noeuds\n",
    "        self._set_color_infected_nodes()\n",
    "        return None\n",
    "            \n",
    "    def get_nb_infected_nodes(self) -> int:\n",
    "        \"\"\"Retourne le nombre de noeuds infectés\"\"\"\n",
    "        return np.sum(self.sis_nodes)\n",
    "\n",
    "    def get_nb_healthy_nodes(self) -> int:\n",
    "        \"\"\"Retourne le nombre de noeuds succeptibles\"\"\"\n",
    "        return self.sis_N - np.sum(self.sis_nodes)\n",
    "        \n",
    "    @staticmethod\n",
    "    def create_network(n, p, network_path):\n",
    "        \"\"\"Création d'un réseau aléatoire d'Erdos-Renyi\"\"\"\n",
    "        G = nx.Graph()\n",
    "        G.add_nodes_from(range(n))\n",
    "        for i in range(n):\n",
    "            for j in range(i+1, n):\n",
    "                if np.random.rand() < p:\n",
    "                    G.add_edge(i, j)\n",
    "        # Save the graph to the adjlist file\n",
    "        nx.write_adjlist(G, network_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the random seed for reproducibility\n",
    "np.random.seed(0)\n",
    "\n",
    "# Test précédent numéro 4.2 c)\n",
    "#SIS.create_network(10, 0.5, \"data/reseau_petit.adj\")\n",
    "\n",
    "# Create a SIS object\n",
    "# SIS(path_to_network, alpha, beta)\n",
    "# graph = SIS(\"data/reseau_petit.adj\", 0.25, 1)\n",
    "graph = SIS(\"data/reseau.adj\", 0.05, 0.1)\n",
    "pos = nx.kamada_kawai_layout(graph)  # très lisible\n",
    "\n",
    "graph.init_infected(0.1)\n",
    "print(\"Situation initiale\")\n",
    "print(\"Nombre de noeuds infectés :\", graph.get_nb_infected_nodes())\n",
    "print(\"Nombre de noeuds suceptibles :\", graph.get_nb_healthy_nodes())\n",
    "nx.draw(graph, pos, with_labels=True, node_color=graph.sis_nodes_colors, node_size=300)\n",
    "plt.show()\n",
    "\n",
    "graph.simulate_multiple_iteration(100)\n",
    "print(\"Situation après 100 itérations\")\n",
    "print(\"Nombre de noeuds infectés :\", graph.get_nb_infected_nodes())\n",
    "print(\"Nombre de noeuds suceptibles :\", graph.get_nb_healthy_nodes())\n",
    "nx.draw(graph, pos, with_labels=True, node_color=graph.sis_nodes_colors, node_size=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lorsque l'on simule pour un simple scénario, nous observons que le nombre de noeuds infectés est initialisé à 12. Après 100 pas de temps, il y a un totale de 89 noeuds qui sont contaminés. Allons voir si ce résultats est en accordance avec la majortié. Pour ce faire nous reproduirons cette simulations pour 100 scénarios différents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the random seed for reproducibility\n",
    "np.random.seed(0)\n",
    "\n",
    "nb_simulations = 100\n",
    "nb_infected_nodes = np.zeros(nb_simulations)\n",
    "nb_healthy_nodes = np.zeros(nb_simulations)\n",
    "\n",
    "for i in range(nb_simulations):\n",
    "    graph = SIS(\"data/reseau.adj\", 0.05, 0.1)\n",
    "    graph.init_infected(0.1)\n",
    "    graph.simulate_multiple_iteration(100)\n",
    "\n",
    "    nb_infected_nodes[i] = graph.get_nb_infected_nodes()\n",
    "    nb_healthy_nodes[i] = graph.get_nb_healthy_nodes()\n",
    "\n",
    "print(f\"Nombre de noeuds infectés : {np.mean(nb_infected_nodes):.2f}\")\n",
    "print(f\"Nombre de noeuds suceptibles : {np.mean(nb_healthy_nodes):.2f}\")\n",
    "print(f\"Ecart-type du nombre de noeuds infectés : {np.std(nb_infected_nodes):.2f}\")\n",
    "print(f\"Ecart-type du nombre de noeuds suceptibles : {np.std(nb_healthy_nodes):.2f}\")\n",
    "\n",
    "# Fit gaussien infectés\n",
    "mean = np.mean(nb_infected_nodes)\n",
    "std = np.std(nb_infected_nodes)\n",
    "x = np.linspace(mean - 3*std, mean + 3*std, 100)\n",
    "y = (1/(std * np.sqrt(2 * np.pi))) * np.exp(-0.5 * ((x - mean) / std)**2)\n",
    "plt.plot(x, y, color='red', label='Fit gaussien')\n",
    "plt.hist(nb_infected_nodes, bins=15, density=True, alpha=0.5)\n",
    "plt.title(\"Distribution du nombre de noeuds infectés après 100 itérations\")\n",
    "plt.xlabel(\"Nombre de noeuds infectés\")\n",
    "plt.ylabel(\"Densité de probabilité\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Fit gaussien suceptibles\n",
    "mean = np.mean(nb_healthy_nodes)\n",
    "std = np.std(nb_healthy_nodes)\n",
    "x = np.linspace(mean - 3*std, mean + 3*std, 100)\n",
    "y = (1/(std * np.sqrt(2 * np.pi))) * np.exp(-0.5 * ((x - mean) / std)**2)\n",
    "plt.plot(x, y, color='red', label='Fit gaussien')\n",
    "plt.hist(nb_healthy_nodes, bins=15, density=True, alpha=0.5)\n",
    "plt.title(\"Distribution du nombre de noeuds suceptibles après 100 itérations\")\n",
    "plt.xlabel(\"Nombre de noeuds suceptibles\")\n",
    "plt.ylabel(\"Densité de probabilité\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lorsque l'on simule 100 scénario différents, nous observons qu'en moyenne 89 noeuds sont infectés. Cela est en accordance avec le simple scénario réalisé à l'étape précédente. Nous observons aussi que l'écart-type est de 3 noeuds. La distribution semble être un distribution gaussienne. C'est pourquoi un fit gaussi a été appliqué à nos données. Maintenant, observons comment le taux d'infection varie en moyenne selon le pas de temps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the random seed for reproducibility\n",
    "np.random.seed(0)\n",
    "\n",
    "nb_simulations = 100\n",
    "nb_steps = 100\n",
    "nb_infected_nodes_at_t = np.zeros(nb_simulations)\n",
    "nb_healthy_nodes_at_t = np.zeros(nb_simulations)\n",
    "nb_infected_nodes = np.zeros(nb_steps)\n",
    "nb_healthy_nodes= np.zeros(nb_steps)\n",
    "\n",
    "massive_array_of_graphs = np.zeros(nb_simulations, dtype=SIS)\n",
    "\n",
    "# We create a SIS object for each simulation\n",
    "for i in range(nb_simulations):\n",
    "    graph = SIS(\"data/reseau.adj\", 0.05, 0.1)\n",
    "    graph.init_infected(0.1)\n",
    "    massive_array_of_graphs[i] = graph\n",
    "\n",
    "for t in range(nb_steps):\n",
    "    # On simule une itération du modèle SIS pour chaque graph\n",
    "    for i, graph in enumerate(massive_array_of_graphs):\n",
    "        # On simule une itération du modèle SIS\n",
    "        graph.simulate_one_iteration()\n",
    "\n",
    "        nb_infected_nodes_at_t[i] = graph.get_nb_infected_nodes()\n",
    "        nb_healthy_nodes_at_t[i] = graph.get_nb_healthy_nodes()\n",
    "    \n",
    "    # On met à jour le tableau des noeuds\n",
    "    nb_infected_nodes[t] = np.mean(nb_infected_nodes_at_t)\n",
    "    nb_healthy_nodes[t] = np.mean(nb_healthy_nodes_at_t)\n",
    "    # On réinitialise le tableau temporaire\n",
    "    nb_healthy_nodes_at_t[:] = 0\n",
    "    nb_infected_nodes_at_t[:] = 0\n",
    "\n",
    "plt.plot(nb_infected_nodes, label=\"Infectés\")\n",
    "plt.plot(nb_healthy_nodes, label=\"Suceptibles\")\n",
    "plt.title(\"Evolution du nombre de noeuds infectés et suceptibles\")\n",
    "plt.xlabel(\"Pas de temps\")\n",
    "plt.ylabel(\"Nombre de noeuds\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(nb_infected_nodes[:40], label=\"Infectés\")\n",
    "plt.plot(nb_healthy_nodes[:40], label=\"Suceptibles\")\n",
    "plt.title(\"Evolution du nombre de noeuds infectés et suceptibles\")\n",
    "plt.xlabel(\"Pas de temps\")\n",
    "plt.ylabel(\"Nombre de noeuds\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tout comme dans la figure 4.1 b), on observe que le nombre de nœuds infectés augmente de manière linéaire durant les premiers pas de temps, avant de se stabiliser autour d’une valeur donnée. Lorsqu’on examine uniquement les 40 premiers pas de temps, la courbe obtenue ressemble fortement à celle de la figure 4.1 b). En effet, les tout premiers instants présentent une pente relativement faible, suivis d’une phase de croissance linéaire plus marquée, jusqu’à atteindre un plateau. Cependant, assumons que les variable $\\alpha$ et $\\beta$ possède la même signification à l'étape 4.1, nous remarquons que dans cette situation la propagation est grande. En effet, dans notre situation, nous avons un $I_0 = 0.1$ ainsi qu'un $R_0 = 2$. À l'étape une telle situation se stabilise avec un taux de contamination de 50% tandis que dans notre cas nous observons un taux de contamination près de 90%.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Références"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[1] https://progresser-en-maths.com/loi-binomiale-cours-et-exercices-corriges/#Definition_a_laide_depreuves_de_Bernoulli"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
